openapi: 3.0.0
servers:
  - url: https://llm-agent.aplisay.com/api
info:
  title: LLM Agent API
  version: 1.0.0
  description: |-
    Simple platform agnostic API to create, update and monitor agents connecting inbound audio sessions to 
    a large language model (LLM) based AI engine.

    Extensible architecture that currently supports the following frameworks:
      * Jambonz: connecting LLMs to telephone calls via an STT->model->TTS pipeline (15 models, any STT,TTS supported by Jambonz)
      * Livekit: connecting LLMs to WebRTC rooms and SIP calls using the RealTime Agents API (traditional STT/TTS pipeline agents coming soon)
      * Ultravox: connecting LLMs to WebRTC rooms and SIP calls using the Ultravox API and SDK.
      
    Allows the LLM parameters such as `prompt` and `temperature` to be set at agent creation time and later modified via updates which affect all future calls.
    Also allows setting and modification of text to speech (TTS) and speech to text (STT) parameters which are used for voice recognition and voicing of responses.

    Provides a websocket based `progess` interface which communicates events which take place on calls, allowing the controlling software to capture data and modify
    the prompt in response to client interaction.

    For a demo of the API in action without writing any code, try out the [Aplisay LLM playground](https://llm.aplisay.com), a hosted React based front-end.

    Typical simple transaction flow will be:
      
    1. **[GET models](#operations-Models-modelList)** to obtain a list of valid models.
    2. **[POST agents](#operations-Agent-createAgent)** with a chosen model identifier and prompt to create an agent.
    3. **[POST listen](#operations-Agent-activate)** with the agent ID and type to receive an `instanceId` and either
       a `number` or livekit/ultravox room values from the create call result.
    4. Open a new livekit client session and join the room to receive transcript updates and send/receive audio, or call the number.
    5. When done with the agent, shut down the listener **[DELETE /listener/{listenerId}](#operations-Agent-deleteListenerById)**.
    6. Call **[DELETE agents/{id}](#operations-Agent-deleteAgent)**.

tags:
  - name: Calls
    description: |-
      Call objects are created when an agent receives a call from an external caller
      and are destroyed when the dialogue is complete and either agent or caller hang up.
      Calls operations are always referenced by parent agent and allow listing of live calls, live updating of agent parameters mid-call
      for just one call, injection of direct speech by the app, and hanging up a call by the agent.
  - name: Agent
    description: |-
      An Agent is the core of this API. It describes the interface to an AI engine which operates using a prompt, specifies any
      options like speech recognition language or output voice, temperature and other LLM parameters as well as tools
      (API) calls that a capable LLM may use to fulfill requests.
      An instance of an Agent is created by POSTing to the `/agents` endpoint, and then one or more instances may be activated
      using the `listen` verb to cause implementation specific worker plugins to then execute them to service inbound SIP or WebRTC 
      calls.
  - name: Models
    description: |-
      A Model is an AI language model provider which is used by an Agent and controlled through a prompt.
      The Model for a particular agent is set at agent creation time.
  - name: Voices
    description: |-
      Voices are the list of text to speach (TTS) voices which are available in the engine, again they are
      set at agent creation time, but may also be modified in the course of running an agent.
  - name: Phone Endpoints
    description: |-
      Phone Endpoints represent routed telephone numbers and other SIP user fields available to an organisation for use with agents.
      These endpoints can be assigned to agent instances to handle incoming calls to the DDI or SIP registration ID
  - name: Listeners
    description: |-
      Listener operations manage agent listener instances, including activation, join, originate, and deletion.

components:
  schemas:
    Model:
      type: object
      properties:
        name:
          description: Model Name
          type: string
          example: GPT3.5-turbo
        description:
          description: Agent Description
          type: string
          example: GPT3.5-turbo chat
        voices:
          $ref: "#/components/schemas/VoiceList"
        supportsFunctions:
          description: This model supports function calling via the `functions` property
          type: boolean
          example: true
        audioModel:
          description: This model is a speech-to-speech audio model
          type: boolean
          example: false
        hasTelephony:
          description: This model has a telephony interface so can be activated with a number if required
          type: boolean
          example: true
        hasWebRTC:
          description: This model supports audio input via WebRTC
          type: boolean
          example: true
      required:
        - name
        - description
    Agent:
      type: object
      properties:
        modelName:
          $ref: "#/components/schemas/ModelName"
        prompt:
          $ref: "#/components/schemas/Prompt"
        options:
          $ref: "#/components/schemas/AgentOptions"
        functions:
          $ref: "#/components/schemas/Functions"
        keys:
          $ref: "#/components/schemas/Keys"
    ModelName:
      type: string
      description: The short model name
      example: gpt35
    Parameters:
      type: object
      description: |-
        An OpenAPI style schema for the invocation parameters.
        There are three types of parameter as defined by the source property: `generated`, `static`, `metadata`:
          
         * `generated` parameters (default) are generated by the LLM dynamically based on its conversation context. They are used for things 
        that the LLM knows or has found out.
         * `static` parameters that are invariant and will be the same on each function call, their definition is a fixed value from the `from` field.
         * `metadata` parameters are used to pass per call or invocation variant data to the function, the `from` field is a text key to the metadata object.

        `static` and `metadata` parameters are not seen by the LLM (unless a function call returns them in it's results), but are added to the function call after dispatch by the LLM.
      properties:
        properties:
         type: object
         additionalProperties:
           type: object
           description: A parameter for a function call
           properties:
             name:
               type: string
               description: The name of the parameter
               example: temperature
             description:
               type: string
               description: >
                 If the parameter is `generated` then this property is essential and is a description of what the parameter does and how it should be set which 
                 will be used by the LLM to shape the input. Careful specification of the syntax and semantics of the parameter here is essential for reliable function
                 invocation by the LLM.
               example: The city name to be looked up.
             type:
               type: string
               description: The type of the parameter
               default: "string"
               enum: ["string", "number", "boolean"]
             in:
               type: string
               description: Where in the request the parameter should be used
               enum: ["body", "header", "path", "query"]
               default: "query"
               example: query
             required:
               type: boolean
               description: Whether this parameter is required
               default: false
               example: true
             source:
               type: string
               description: The type of the parameter
               enum: ["generated", "static", "metadata"]
               default: "generated"
               example: "static"
             from:
               type: string
               description: |-
                 The source value of the parameter for `static` or `metadata` parameters, either a constant string value for `static` parameters, or a key to the metadata object for `metadata` parameters.
                 Metadata keys consist of one or two levels of keys separated by a dot. 
                 All builtin keys sit under an `aplisay` top level namespace, e.g. `aplisay.callerId`, `aplisay.isWebrtc`.
                 Custom metadata keys can be added by the caller in certain setup calls.
                 Whilst these can be any string, it is recommended to use a namespace to avoid clashes, *e.g.* `myapp.mykey`.
               example: aplisay.callerId
      example:
        properties:
          location:
            type: string
            description: The city and country, e.g. London, UK
            required: true
          units:
            type: string
            enum: ["celsius", "fahrenheit"]
            description: The unit of temperature, either \"celsius\" or \"fahrenheit\"
          caller_id:
            type: string
            source: metadata
            from: aplisay.callerId
          userData:
            type: string
            source: metadata
            from: myapp.userData
          someStaticParam:
            type: string
            source: static
            from: "some value"

    Prompt:
      type: string
      description: The prompt to be used in the LLM engine
      example: |-
        You work for Robs Flags, a company that manufactures flags.
        You can only chat with callers about submitting or organising the return of an order that the user has previously made...
    AgentOptions:
      type: object
      properties:
        temperature:
          description: Agent LLM temperature
          type: number
          example: 0.2
        tts:
          type: object
          properties:
            language:
              $ref: "#/components/schemas/Language"
            voice:
              description: |-
                TTS voice specifier.
                Must be a supported voice language as returned from a get on the `voices` api
              type: string
              example: en-GB-Wavenet-A
        stt:
          type: object
          properties:
            language:
              $ref: "#/components/schemas/Language"
        fallback:
          type: object
          properties:
            number:
              description: |-
                A phone number to try transferring the call to if the LLM is unavailable or not responding (telephone agents only)
                If the LLM is unavailable or not responding, the call will be transferred to this number.

                This fallback number will also be available as metadata for use in function calls as `aplisay.fallbackNumber`.
                It can be used there to actively trigger a fallback to a human agent by the LLM by arranging for it to call the `platform` function `transfer` with the number as a parameter.
              type: string
              example: "+44123456780"
        callbackUrl:
          $ref: "#/components/schemas/CallbackUrl"
    CallbackUrl:
      type: string
      description: A callback URL to be used for status updates
      example: https://app.aplisay.com/status/updates
    Functions:
      type: array
      description: An array of fulfillment functions to be given to the LLM as tools
      items:
        type: object
        properties:
          name:
            type: string
            description: The function call name, used in the invocation, this is an arbitrary string identifier.
            pattern: '^[a-zA-Z0-9_-]{1,64}$'
            example: get_weather
          description:
            type: string
            description: A description of what the function call does which will be used by the LLM when deciding to invoke it
            example: Get the current weather in a given location
          implementation:
            type: string
            description: |-
              How this function should be implemented.
              * `stub` is used to return the same fixed result each time for testing,
              * `rest` makes an actual API call using *url* and the rest of the parameters
              * `client` is a client side function that is implemented in the client code (only useful for WebRTC agents)
              * `builtin` is a function that is built into the Aplisay LLM platform.
            enum: ["rest", "stub", "client", "builtin"]
            example: rest
          platform:
            type: string
            enum: ["hangup", "transfer", "metadata"]
            description: >  
                For `builtin` functions, this is the name of a platform function as defined in the platform. The following platform functions are currently available:
                  * `hangup` takes no parameters and will hang up the call
                  * `metadata` interrogates the metadata for the call, returning a JSON object with the requested metadata keys and values. 
                     Keys are specified as a comma separated list in the `keys` parameter.
                  * `transfer` will transfer the call to a number specified in the `number` parameter. Optionally, you may also supply:
                    - `callerId` (string): override the caller ID used for the transfer
                    - `operation` (string): specify a transfer operation/mode used by the underlying platform; allowed values are `blind` (default), `consult_start`, `consult_finalise`, `consult_reject`
                
                Note that the transfer function will only be available to telephone agents, and the `number` parameter 
                can only be specified as either `static` or `metadata` (e.g. from `aplisay.transferNumber` metadata.
                For anti-fraud reasons, it is not possible to use a LLM `generated` parameter as the number to transfer a call to.

                The `metadata` function will only currently be available to telephone agents, and the `keys` parameter 
                can only be specified as a `static`. This ensures that the LLM can only work with metadata that the agent designer
                has explicitly allowed it to which is a security feature to control the risk of data leakage.

          result:
            type: string
            description: The hardwired result of this function call, optional and only useful for `stub` or `client`
            example: the result is one
          url:
            type: string
            description: The URL to be called when the function is invoked, optionally with path variable substitutions wrapped in {} braces
            example: https://app.aplisay.com/weather/get_weather/{location}
          method:
            type: string
            description: The HTTP method to be used when calling the function
            enum: ["get", "post", "put", "delete"]
            example: get
          key:
            type: string
            description: The name of an API key which should be used with this call
            example: WEATHER_API_KEY
          input_schema:
            $ref: "#/components/schemas/Parameters"
    Keys:
      type: array
      description: An array of keys to be used in API calls
      items:
        type: object
        properties:
          name:
            type: string
            description: The key name, used in the invocation
            example: get_weather
          in:
            type: string
            description: Where in the request the key should be used
            enum: ["basic", "bearer", "header", "path", "query"]
            example: bearer
          value:
            type: string
            description: The value of the key. For keys in the \"basic\" auth header, this will be the base64 encoded value of the username:password
            example: asdk438smw03lxdfs9se3
          username:
            type: string
            description: The username for the key. Meaningful only for keys in the \"basic\" auth header.
            example: user1
          header:
            type: string
            description: The custom header name for the key. Meaningful only for keys with an `in` of \"header\".
            example: X-Api-Key
          password:
            type: string
            description: The password for the key. Meaningful only for keys in the \"basic\" auth header.
            example: <PASSWORD>
    Language:
      description: >-
        Language and country dialect specified as an ISO639-1 language code
        followed by a dash and and ISO3166 country code.
        For now, list of supported recognition voices is identical to the voicing languages returned from the `voices` api.
        This should change in future
      type: string
    Voice:
      type: object
      properties:
        name:
          type: string
          description: The voice name or identifier within the TTS engine - opaque string
          example: en-GB-Wavenet-B
        gender:
          type: string
          description: The vendor assigned gender of this voice within the TTS engine
          example: male
    VoiceList:
      type: object
      additionalProperties:
        type: object
        additionalProperties:
          type: object
          additionalProperties:
            type: array
            items:
              $ref: "#/components/schemas/Voice"
    TransactionLog:
      type: array
      description: An array of log entries for this transaction
      items:
        $ref: "#/components/schemas/TransactionLogRow"
    TransactionLogRow:
      type: object
      properties:
        callId:
          type: string
          description: unique ID of this transaction
          example: 648aa45d-204a-4c0c-a1e1-419406254134
        type:
          type: string
          description: The type of this log entry
          enum: ["call", "agent", "user", "hangup"]
          example: call
        data:
          type: string
          description: The data associated with this log entry
          example: "hello, how may a I help you"
        createdAt:
          type: string
          description: The time this log entry was created
          example: 2020-01-01T00:00:00Z
        updatedAt:
          type: string
          description: The time this log entry was last updated
          example: 2020-01-01T00:00:00Z
        isFinal:
          type: boolean
          description: Whether this log entry is the final form for this row, if false, then the row may change in future (e.g. to add further transcriptions)
          example: true
    Call:
      type: object
      properties:
        id:
          type: string
          description: unique ID of this call
          example: 648aa45d-204a-4c0c-a1e1-419406254134
        agentId:
          type: string
          description: The ID of the agent that this call is associated with
          example: 648aa45d-204a-4c0c-a1e1-419406252234
        from:
          type: string
          description: Caller number (as received, no format guaranteed)
          example: "03300889471"
        to:
          type: string
          description: Called number for this call
          example: "+442080996945"
        startedAt:
          type: string
          description: The time this call started
          example: 2025-06-04T12:00:00.000Z
        endedAt:
          type: string
          description: The time this call ended
          example: 2025-06-04T12:01:00.000Z
    CallId:
      type: string
      description: The Call ID the event relates to
      example: 648aa45d-204a-4c0c-a1e1-419406254134
    Progress:
      oneOf:
        - $ref: "#/components/schemas/Progress.user"
        - $ref: "#/components/schemas/Progress.agent"
        - $ref: "#/components/schemas/Progress.inject"
        - $ref: "#/components/schemas/Progress.call"
        - $ref: "#/components/schemas/Progress.hangup"
        - $ref: "#/components/schemas/Progress.data"
      example:
        {
          prompt: "I would like some candyfloss",
          call_id: "648aa45d-204a-4c0c-a1e1-419406254134",
        }
    Progress.user:
      type: object
      properties:
        user:
          type: string
          description: prompt received from user
          example: I would like some candyfloss
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.agent:
      type: object
      properties:
        agent:
          type: string
          description: completion from AI to user
          example: I am an AI I cannot make physical things like candyfloss
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.inject:
      type: object
      properties:
        inject:
          type: string
          description: spoken text injected directly by the application
          example: This is your application speaking
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.call:
      type: object
      properties:
        call:
          type: string
          description: the phone number of the caller
          example: +44123456789
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.hangup:
      type: object
      properties:
        hangup:
          type: boolean
          description: boolean true value to indicate hangup
          example: true
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.data:
      type: object
      properties:
        data:
          type: object
          description: "raw JSON data object as sent by the AI model"
          example: { order: { number: 123456, value: "Â£12345" } }
        call_id:
          $ref: "#/components/schemas/CallId"
    Error:
      type: object
      properties:
        code:
          type: string
          description: String representation of a numeric error code
          example: "1234"
        message:
          type: string
          description: Human readable error condition (largely) suitable to present to the client.
          example: "general server error"
    NotFound:
      type: object
      properties:
        message:
          type: string
          description: Human readable message describing which parameter was not found
          example: "Not found: no phone number matching 1234 exists for this user/organisation"
    Conflict:
      type: object
      properties:
        message:
          type: string
          description: Human readable message describing which parameter was in conflct
          example: "In use: number 1234 is already linked to another instance"
    PreConditionFailed:
      type: object
      properties:
        message:
          type: string
          description: Human readable message describing which condition failed
          example: "Not supported: 1234 routes to jambonz but this agent uses livekit"
paths: {}
