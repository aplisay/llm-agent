openapi: 3.0.0
servers:
  - url: https://llm-backend.aplisay.com/api
info:
  title: LLM Agent API
  version: 1.0.0
  description: |-
    Simple API to create, update and monitor agents connecting inbound telephone calls to 
    a large language model (LLM) based AI engine via Jambonz.

    Allows the LLM parameters such as `prompt` and `temperature` to be set at agent creation time and later modified via updates which affect all future calls.
    Also allows setting and modification of text to speech (TTS) and speech to text (STT) parameters which are used for voice recognition and voicing of responses.
    
    Provides a websocket based `progess` interface which communicates events which take place on calls, allowing the controlling software to capture data and modify
    the prompt in response to client interaction.

    For a demo of the API in action without writing any code, try out the [Aplisay LLM playground](https://llm.aplisay.com), a hosted React based front-end.

    Typical simple transaction flow will be:
      
    1. **[GET models](#operations-Models-modelList)** to obtain a list of valid models.
    2. **[POST agents](#operations-Agent-createAgent)** with a chosen model identifier and prompt to create an agent.
    3. Obtain the `number` and `socket` values from the create call result.
    4. Open a new Websocket client to the URL returned in `socket`, and listen on results.
    5. Place calls to the returned `number`, observing the progress updates on the websocket.
    6. When done with the agent, close the websocket client.
    7. Call **[DELETE agents/{id}](#operations-Agent-deleteAgent)**.

    The above is sufficient for a naive agent that simply operates from a single prompt for the duration of the call as a demo of LLMs interacting with telephone callers.

    More sophisticated agents will invariably be built by using logic and data to interact with the agent and modify behaviour throughout a call transaction.
    This is done via the `socket` event stream to follow the conversation, and the `Calls` methods to dynamically change the agent system prompt, inject
    phrases directly into the call, or hang it up if necessary.

tags:
  - name: Calls
    description: |-
      Call objects are created when an agent receives a call from an external caller
      and are destroyed when the dialogue is complete and either agent or caller hang up.
      Calls operations are always referenced by parent agent and allow listing of live calls, live updating of agent parameters mid-call
      for just one call, injection of direct speech by the app, and hanging up a call by the agent.
  - name: Agent
    description: |-
      An Agent is the core of this API. It describes an AI engine which operates using a prompt and is connected to a single phone 
      number for inbound calls.
  - name: Models
    description: |-
      A Model is an AI language model provider which is used by an Agent and controlled through a prompt.
      The Model for a particular agent is set at agent creation time.
  - name: Voices
    description: |-
      Voices are the list of text to speach (TTS) voices which are available in the engine, again they are
      set at agent creation time, but may also be modified in the course of running an agent.

components:
  schemas:
    Model:
      type: object
      properties:
        name:
          description: Model Name
          type: string
          example: GPT3.5-turbo
        description:
          description: Agent Description
          type: string
          example: GPT3.5-turbo chat
        defaultPrompt:
          description: A working initial default prompt for this agent
          type: string
          example: You are a helpful agent...
        voices:
          $ref: '#/components/schemas/VoiceList'
        supportsFunctions:
          description: This model supports function calling via the `functions` property
          type: boolean
          example: true
        audioModel:
          description: This model supports audio input via WebRTC
          type: boolean
          example: false
      required:
        - name
        - defaultPrompt
    Agent:
      type: object
      properties:
        modelName:
          $ref: '#/components/schemas/ModelName'
        prompt:
          $ref: '#/components/schemas/Prompt'
        options:
          $ref: '#/components/schemas/AgentOptions'
    ModelName:
      type: string
      description: The short model name
      example: gpt35
    Prompt:
      type: string
      description: The prompt to be used in the LLM engine
      example: |-
        You work for Robs Flags, a company that manufactures flags.
        You can only chat with callers about submitting or organising the return of an order that the user has previously made...
    AgentOptions:
      type: object
      properties:
        temperature:
          description: Agent LLM temperature
          type: number
          example: 0.2
        tts:
          type: object
          properties:
            language:
              $ref: '#/components/schemas/Language'
            voice:
              description: |-
                TTS voice specifier.
                Must be a supported voice language as returned from a get on the `voices` api
              type: string
              example: en-GB-Wavenet-A
        stt:
          type: object
          properties:
            language:
              $ref: '#/components/schemas/Language'
    CallbackUrl:
      type: string
      description: A callback URL to be used for status updates
      example: https://app.aplisay.com/status/updates
    Functions:
      type: array
      description: An array of fulfillment functions to be given to the LLM as tools
      items:
        type: object
        properties:
          name:
            type: string
            description: The function call name, used in the invocation
            example: get_weather
          description:
            type: string
            description: A description of what the function call does which will be used by the LLM when deciding to invoke it
            example: Get the current weather in a given location
          input_schema:
            type: object
            description: An OpenAPI style schema for the invocation parameters
            example:
              type: object
              properties:
                location:
                  type: string
                  description: The city and country, e.g. London, UK
                units:
                  type: string
                  enum: ['celsius', 'fahrenheit']
                  description: The unit of temperature, either \"celsius\" or \"fahrenheit\"
              required: ['location']
    Language:
      description: >-
        Language and country dialect specified as an ISO639-1 language code
        followed by a dash and and ISO3166 country code.
        For now, list of supported recognition voices is identical to the voicing languages returned from the `voices` api.
        This should change in future
      type: string
    Voice:
      type: object
      properties:
        name:
          type: string
          description: The voice name or identifier within the TTS engine - opaque string
          example: en-GB-Wavenet-B
        gender:
          type: string
          description: The vendor assigned gender of this voice within the TTS engine
          example: male
    VoiceList:
          type: object
          additionalProperties:
            type: object
            additionalProperties:
              type: array
              items:
                $ref: '#/components/schemas/Voice'
    Call:
      type: object
      properties:
        id:
          type: string
          description: unique ID of this call
          example: 648aa45d-204a-4c0c-a1e1-419406254134
        from:
          type: string
          description: Caller number (as received, no format guaranteed)
          example: "03300889471"
        to:
          type: string
          description: Called number for this call 
          example: "+442080996945"
    CallId:
      type: string
      description: The Call ID the event relates to
      example: 648aa45d-204a-4c0c-a1e1-419406254134
    Progress:
      oneOf:
        - $ref: '#/components/schemas/Progress.user'
        - $ref: '#/components/schemas/Progress.agent'
        - $ref: '#/components/schemas/Progress.inject'
        - $ref: '#/components/schemas/Progress.call'
        - $ref: '#/components/schemas/Progress.hangup'
        - $ref: '#/components/schemas/Progress.data'
      example: { prompt: "I would like some candyfloss", call_id: "648aa45d-204a-4c0c-a1e1-419406254134"}
    Progress.user:
      type: object
      properties:
        user:
          type: string
          description: prompt received from user
          example: I would like some candyfloss
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.agent:
      type: object
      properties:
        agent:
          type: string
          description: completion from AI to user
          example: I am an AI I cannot make physical things like candyfloss
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.inject:
      type: object
      properties:
        inject:
          type: string
          description: spoken text injected directly by the application
          example: This is your application speaking
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.call:
      type: object
      properties:
        call:
          type: string
          description: the phone number of the caller
          example: +44123456789
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.hangup:
      type: object
      properties:
        hangup:
          type: boolean
          description: boolean true value to indicate hangup
          example: true
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.data:
      type: object
      properties:
        data:
          type: object
          description: "raw JSON data object as sent by the AI model"
          example: { order: { number: 123456, value: 'Â£12345'}}
        call_id:
          $ref: "#/components/schemas/CallId"
    Error:
      type: object
      properties:
        code:
          type: string
          description: String representation of a numeric error code
          example: "1234"
        message:
          type: string
          description: Human readable error condition (largely) suitable to present to the client.
          example: "general server error"
    NotFound:
      type: object
      properties:
        message:
          type: string
          description: Human readable message describing which parameter was not found
          example: ThingID 1234 not found.
paths: {}
