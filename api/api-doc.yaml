openapi: 3.0.0
servers:
  - url: https://llm-backend.aplisay.com/api
info:
  title: LLM Agent API
  version: 1.0.0
  description: |-
    Simple platform agnostic API to create, update and monitor agents connecting inbound audio sessions to 
    a large language model (LLM) based AI engine.

    Extensible architecture that currently supports the following frameworks:
      * Jambonz: connecting LLMs to telephone calls via an STT->model->TTS pipeline (15 models, any STT,TTS supported by Jambonz)
      * Livekit: connecting LLMs to WebRTC rooms and SIP calls using the RealTime Agents API (traditional STT/TTS pipeline agents coming soon)
      * Ultravox: connecting LLMs to WebRTC rooms and SIP calls using the Ultravox API and SDK.
      
    Allows the LLM parameters such as `prompt` and `temperature` to be set at agent creation time and later modified via updates which affect all future calls.
    Also allows setting and modification of text to speech (TTS) and speech to text (STT) parameters which are used for voice recognition and voicing of responses.
    
    Provides a websocket based `progess` interface which communicates events which take place on calls, allowing the controlling software to capture data and modify
    the prompt in response to client interaction.

    For a demo of the API in action without writing any code, try out the [Aplisay LLM playground](https://llm.aplisay.com), a hosted React based front-end.

    Typical simple transaction flow will be:
      
    1. **[GET models](#operations-Models-modelList)** to obtain a list of valid models.
    2. **[POST agents](#operations-Agent-createAgent)** with a chosen model identifier and prompt to create an agent.
    3. **[POST listen](#operations-Agent-activate)** with the agent ID and type to receive an `instanceId` and either
       a `number` or livekit/ultravox room values from the create call result.
    4. Open a new livekit client session and join the room to receive transcript updates and send/receive audio, or call the number.
    5. When done with the agent, shut down the listener **[DELETE agents/{id}/listen/{instanceId}](#operations-Agent-deleteListener).
    6. Call **[DELETE agents/{id}](#operations-Agent-deleteAgent)**.

tags:
  - name: Calls
    description: |-
      Call objects are created when an agent receives a call from an external caller
      and are destroyed when the dialogue is complete and either agent or caller hang up.
      Calls operations are always referenced by parent agent and allow listing of live calls, live updating of agent parameters mid-call
      for just one call, injection of direct speech by the app, and hanging up a call by the agent.
  - name: Agent
    description: |-
      An Agent is the core of this API. It describes the interface to an AI engine which operates using a prompt, specifies any
      options like speech recognition language or output voice, temperature and other LLM parameters as well as tools
      (API) calls that a capable LLM may use to fulfill requests.
      An instance of an Agent is created by POSTing to the `/agents` endpoint, and then one or more instances may be activated
      using the `listen` verb to cause implementation specific worker plugins to then execute them to service inbound SIP or WebRTC 
      calls.
  - name: Models
    description: |-
      A Model is an AI language model provider which is used by an Agent and controlled through a prompt.
      The Model for a particular agent is set at agent creation time.
  - name: Voices
    description: |-
      Voices are the list of text to speach (TTS) voices which are available in the engine, again they are
      set at agent creation time, but may also be modified in the course of running an agent.

components:
  schemas:
    Model:
      type: object
      properties:
        name:
          description: Model Name
          type: string
          example: GPT3.5-turbo
        description:
          description: Agent Description
          type: string
          example: GPT3.5-turbo chat
        voices:
          $ref: '#/components/schemas/VoiceList'
        supportsFunctions:
          description: This model supports function calling via the `functions` property
          type: boolean
          example: true
        audioModel:
          description: This model supports audio input via WebRTC
          type: boolean
          example: false
      required:
        - name
        - description
    Agent:
      type: object
      properties:
        modelName:
          $ref: '#/components/schemas/ModelName'
        prompt:
          $ref: '#/components/schemas/Prompt'
        options:
          $ref: '#/components/schemas/AgentOptions'
        functions: 
          $ref: '#/components/schemas/Functions'
        keys: 
          $ref: '#/components/schemas/Keys'
    ModelName:
      type: string
      description: The short model name
      example: gpt35
    Prompt:
      type: string
      description: The prompt to be used in the LLM engine
      example: |-
        You work for Robs Flags, a company that manufactures flags.
        You can only chat with callers about submitting or organising the return of an order that the user has previously made...
    AgentOptions:
      type: object
      properties:
        temperature:
          description: Agent LLM temperature
          type: number
          example: 0.2
        tts:
          type: object
          properties:
            language:
              $ref: '#/components/schemas/Language'
            voice:
              description: |-
                TTS voice specifier.
                Must be a supported voice language as returned from a get on the `voices` api
              type: string
              example: en-GB-Wavenet-A
        stt:
          type: object
          properties:
            language:
              $ref: '#/components/schemas/Language'
        callbackUrl:
          $ref: '#/components/schemas/CallbackUrl'
    CallbackUrl:
      type: string
      description: A callback URL to be used for status updates
      example: https://app.aplisay.com/status/updates
    Functions:
      type: array
      description: An array of fulfillment functions to be given to the LLM as tools
      items:
        type: object
        properties:
          name:
            type: string
            description: The function call name, used in the invocation
            example: get_weather
          description:
            type: string
            description: A description of what the function call does which will be used by the LLM when deciding to invoke it
            example: Get the current weather in a given location
          implementation:
            type: string
            description: How this function should be implemented. \"stub\" is used to return the same fixed result each time for testing, \"rest\" makes an actual API call using *url* and the rest of the parameters 
            enum: ["rest", "stub"]
            example: rest
          url:
            type: string
            description: The URL to be called when the function is invoked, optionally with path variable substitutions wrapped in {} braces
            example: https://app.aplisay.com/weather/get_weather/{location}
          method:
            type: string
            description: The HTTP method to be used when calling the function
            enum: ['get', 'post', 'put', 'delete']
            example: get
          key:
            type: string
            description: The name of an API key which should be used with this call
            example: WEATHER_API_KEY
          input_schema:
            type: object
            description: An OpenAPI style schema for the invocation parameters
            example:
              type: object
              properties:
                location:
                  type: string
                  description: The city and country, e.g. London, UK
                units:
                  type: string
                  enum: ['celsius', 'fahrenheit']
                  description: The unit of temperature, either \"celsius\" or \"fahrenheit\"
              required: ['location']
    Keys:
      type: array
      description: An array of keys to be used in API calls
      items:
        type: object
        properties:
          name:
            type: string
            description: The key name, used in the invocation
            example: get_weather
          in:
            type: string
            description: Where in the request the key should be used
            enum: ['query', 'basic', 'bearer', 'path']
            example: bearer
          value:
            type: string
            description: The value of the key. For keys in the \"basic\" auth header, this will be the base64 encoded value of the username:password
            example: asdk438smw03lxdfs9se3
          username:
            type: string
            description: The username for the key. Meaningful only for keys in the \"basic\" auth header.
            example: user1
          password:
            type: string
            description: The password for the key. Meaningful only for keys in the \"basic\" auth header.
            example: <PASSWORD>
    Language:
      description: >-
        Language and country dialect specified as an ISO639-1 language code
        followed by a dash and and ISO3166 country code.
        For now, list of supported recognition voices is identical to the voicing languages returned from the `voices` api.
        This should change in future
      type: string
    Voice:
      type: object
      properties:
        name:
          type: string
          description: The voice name or identifier within the TTS engine - opaque string
          example: en-GB-Wavenet-B
        gender:
          type: string
          description: The vendor assigned gender of this voice within the TTS engine
          example: male
    VoiceList:
          type: object
          additionalProperties:
            type: object
            additionalProperties:
              type: object
              additionalProperties:
                type: array
                items:
                  $ref: '#/components/schemas/Voice'
    Call:
      type: object
      properties:
        id:
          type: string
          description: unique ID of this call
          example: 648aa45d-204a-4c0c-a1e1-419406254134
        from:
          type: string
          description: Caller number (as received, no format guaranteed)
          example: "03300889471"
        to:
          type: string
          description: Called number for this call 
          example: "+442080996945"
    CallId:
      type: string
      description: The Call ID the event relates to
      example: 648aa45d-204a-4c0c-a1e1-419406254134
    Progress:
      oneOf:
        - $ref: '#/components/schemas/Progress.user'
        - $ref: '#/components/schemas/Progress.agent'
        - $ref: '#/components/schemas/Progress.inject'
        - $ref: '#/components/schemas/Progress.call'
        - $ref: '#/components/schemas/Progress.hangup'
        - $ref: '#/components/schemas/Progress.data'
      example: { prompt: "I would like some candyfloss", call_id: "648aa45d-204a-4c0c-a1e1-419406254134"}
    Progress.user:
      type: object
      properties:
        user:
          type: string
          description: prompt received from user
          example: I would like some candyfloss
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.agent:
      type: object
      properties:
        agent:
          type: string
          description: completion from AI to user
          example: I am an AI I cannot make physical things like candyfloss
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.inject:
      type: object
      properties:
        inject:
          type: string
          description: spoken text injected directly by the application
          example: This is your application speaking
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.call:
      type: object
      properties:
        call:
          type: string
          description: the phone number of the caller
          example: +44123456789
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.hangup:
      type: object
      properties:
        hangup:
          type: boolean
          description: boolean true value to indicate hangup
          example: true
        call_id:
          $ref: "#/components/schemas/CallId"
    Progress.data:
      type: object
      properties:
        data:
          type: object
          description: "raw JSON data object as sent by the AI model"
          example: { order: { number: 123456, value: '£12345'}}
        call_id:
          $ref: "#/components/schemas/CallId"
    Error:
      type: object
      properties:
        code:
          type: string
          description: String representation of a numeric error code
          example: "1234"
        message:
          type: string
          description: Human readable error condition (largely) suitable to present to the client.
          example: "general server error"
    NotFound:
      type: object
      properties:
        message:
          type: string
          description: Human readable message describing which parameter was not found
          example: ThingID 1234 not found.
paths: {}
